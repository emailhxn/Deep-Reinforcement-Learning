# The Environment of DRL
An implementation of the environment of Deep Reinforcement Learning in specific field.

## The Trajectory Environment
A **trajectory environment** for **Mobile Crowdsensing Problem** solved by **DRL**. Including management of participants and tasks, feature extraction of trajectory factors, system state simulation and reward computing, etc.

### 1. Mobile Crowdsensing Problem and DRL

With a massive deployment of mobile devices, crowdsourcing has become a new service paradigm in which a task requester could recruit a batch of participants with a mobile IoT device from our system for quick and accurate results. In a mobile industrial crowdsouring platform, a large amount of data is collected, extracted information and distributed to the requesters.   More information about mobile crowdsensing:https://en.wikipedia.org/wiki/Crowdsensing

The participant selection problem in mobile Crowdsensing has been proved to be a NP-hard problem. We presents a multi-goal participant selection approach to iteratively update the participant selection policy via multi-task deep reinforcement learning. 

### 2. Trajectory Environment


### 3. Dataset
Reference to:Analyzing 1.1 Billion NYC Taxi and Uber Trips, with a Vengeance.

"An open-source exploration of the city's neighborhoods, nightlife, airport traffic, and more, through the lens of publicly available taxi and Uber data."

[1] https://toddwschneider.com/posts/analyzing-1-1-billion-nyc-taxi-and-uber-trips-with-a-vengeance/  
[2] https://github.com/toddwschneider/nyc-taxi-data
